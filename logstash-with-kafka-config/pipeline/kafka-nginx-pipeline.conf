input {
    kafka {
        bootstrap_servers => "${KAKFA_SERVERS:kafka:9092}"
        client_id => "logstash-kafka-nginx"
        codec => json
        topics => ["log-nginx"]
    }
}

filter {
	grok {
        match => { "log" => "${GROK_NGINX_ACCESS}" }
        remove_tag => ["_grokparsefailure"]
        add_tag => ["nginx_access"]
    }

    date {
        match => [ "request_at", "dd/MMM/yyyy:HH:mm:ss Z" ]
        timezone => 'UTC'
        remove_field => [ "request_at" ]
    }

    geoip {
        source => "client_ip"
    }
}

output {
    elasticsearch {
        hosts => [ "${ES_HOST1:elasticsearch}", "${ES_HOST2:elasticsearch}", "${ES_HOST3:elasticsearch}" ]
        user => "${ES_USER}"
        password => "${ES_PASSWORD}"
        index => "logstash-nginx-%{+yyyy.MM.dd}"
    }
}